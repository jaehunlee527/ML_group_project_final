{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Final Project - Final",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf8isM7S63bT"
      },
      "source": [
        "%%capture\n",
        "!pip install yfinance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h25pkSQCG0Nh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9eo6WiKHA_n"
      },
      "source": [
        "\"\"\"\n",
        "Basic Preprocessing to add seasonality and group the data frame into weekly view\n",
        "\"\"\"\n",
        "\n",
        "def df_caller(name):\n",
        "    \"\"\"\n",
        "    Fetches basic trading info about the stock\n",
        "    \n",
        "    :param 1 name: ticker symbol\n",
        "    :return: dataframe including volume, closing price, opening price, high price (during the day), low price\n",
        "    \"\"\"\n",
        "    df = yf.download(name)\n",
        "    if len(df) == 0:\n",
        "        raise NameError\n",
        "\n",
        "    # Fill any NaN values with prior \n",
        "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "    df = df.round(3)\n",
        "\n",
        "    return df\n",
        "  \n",
        "def add_week(df):\n",
        "    \"\"\"\n",
        "    Add starting weekly date to each row - to make our preprocessing easier\n",
        "    \"\"\"\n",
        "    df['Week'] = df.index.to_period('W').map(str).str.split('/').str[0]\n",
        "    \n",
        "    # Add weekday as an integer. {Monday: 1, Tuesday: 2, Wednesday: 3, Thursday: 4, Friday: 5}\n",
        "    df['WeekDay'] = df.index.weekday + 1\n",
        "    return df\n",
        "    \n",
        "def group_into_weekly(df):\n",
        "    \"\"\"\n",
        "    Convert df into weekly table, so that each row contains Monday-Friday data\n",
        "    \"\"\"\n",
        "    # Make a new DataFrame: df_final\n",
        "    df_final = df[df['WeekDay'] == 5].copy()\n",
        "    df_final.index = df_final['Week']\n",
        "    df_final.drop(['Week'], axis=1, inplace=True)\n",
        "    df_final.columns = [str(col) + \"_5\" for col in df_final.columns]\n",
        "    \n",
        "    # Join each weekday (1~4) with the df_final on the 'Week' column  \n",
        "    for i in range(4,0,-1):\n",
        "        df_new = df[df['WeekDay'] == i].copy()    \n",
        "        df_new.index = df_new['Week']\n",
        "        df_new.drop(['Week'], axis=1, inplace=True)\n",
        "        df_new.columns = [str(col) + \"_\" + str(i) for col in df_new.columns]\n",
        "        df_final = df_final.join(df_new, on='Week', how='inner') \n",
        "\n",
        "    # Extract month and append as a feature\n",
        "    df_final['Month'] = pd.to_datetime(df_final.index).month\n",
        "\n",
        "    return df_final\n",
        "\n",
        "def add_movement(df):\n",
        "    # Add target variable : {\"Up\": 2, \"Same\": 1, \"Down\": 0}\n",
        "    delta = df.shift(-1)['Close_5'] - df['Close_5'] \n",
        "    df['Target'] = np.where(delta > 0, 1, 0)\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG1vdTgELT2R"
      },
      "source": [
        "\"\"\"\n",
        "Add relevant financial indicators as new features\n",
        "\"\"\"\n",
        "\n",
        "def moving_average(df, days):\n",
        "    \"\"\"\n",
        "    Calculates moving average of closing prices\n",
        "    \n",
        "    :param 1 df\n",
        "    :param 2 days: days of window to calculate moving average\n",
        "    :return: pandas series MA values\n",
        "    \"\"\"\n",
        "    ma = df['Close'].rolling(window = days, min_periods=1).mean()\n",
        "    ma = ma.round(3)\n",
        "    return ma\n",
        "\n",
        "\n",
        "def macd_hist(df):\n",
        "    \"\"\"\n",
        "    Moving Average Convergence Divergence with respect to closing price - Based on difference between 12 & 26 day exponential moving average\n",
        "    \"\"\"\n",
        "    exp1 = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "    exp2 = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "    macd = exp1 - exp2\n",
        "    \n",
        "    signal = macd.ewm(span=9, adjust=False).mean()\n",
        "    hist = macd - signal\n",
        "    \n",
        "    return hist\n",
        "\n",
        "\n",
        "def bollinger(df):\n",
        "    \"\"\"\n",
        "    Bollinger Bands Calcluation with respect to closing prices\n",
        "    \"\"\"\n",
        "    price = (df['Close'] + df['High'] + df['Low']) / 3\n",
        "    sma = moving_average(df, '20D')\n",
        "    upper = sma + 2 * df['Close'].rolling('20D').std()\n",
        "    lower = sma - 2 * df['Close'].rolling('20D').std()\n",
        "    \n",
        "    return (price - lower) / (upper - lower) \n",
        "\n",
        "def rsi(df, days):\n",
        "    \"\"\"\n",
        "    RSI calculation with respect to closing prices\n",
        "    \"\"\"\n",
        "    delta = df['Close'].diff()\n",
        "    \n",
        "    up = delta.clip(lower=0)\n",
        "    down = -1 * delta.clip(upper=0)\n",
        "\n",
        "    ma_up = up.rolling(window = days, min_periods=1).mean()\n",
        "    ma_down = down.rolling(window = days, min_periods=1).mean()\n",
        "\n",
        "    res = ma_up / ma_down\n",
        "    res = 100 - (100/(1 + res))\n",
        "\n",
        "    return res\n",
        "\n",
        "def obv(df):\n",
        "    res = []\n",
        "    for i in range(0, len(df)):\n",
        "        if i == 0:\n",
        "            res.append(df.Volume[i])\n",
        "        elif df.Close[i] > df.Close[i-1]:\n",
        "            res.append(res[-1] + df.Volume[i])\n",
        "        elif df.Close[i] < df.Close[i-1]:\n",
        "            res.append(res[-1] - df.Volume[i])\n",
        "        else:\n",
        "            res.append(res[-1])\n",
        "    \n",
        "    return np.array(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l2g-nydHGPA"
      },
      "source": [
        "def preprocessing(symbol):\n",
        "    # Create df with the company's ticker symbol - Apple Inc. in our example\n",
        "    df = df_caller(symbol)\n",
        "\n",
        "    # Add basic financial indicators as features\n",
        "    df['MACD'] = macd_hist(df)\n",
        "    df['Bollinger'] = bollinger(df)\n",
        "    df['RSI'] = rsi(df, 14)\n",
        "    df['OBV'] = obv(df)\n",
        "\n",
        "    df = df.fillna(method='bfill')\n",
        "\n",
        "    # Scale the indicators \n",
        "    scaler = StandardScaler()\n",
        "    df_scaled = scaler.fit_transform(df[['OBV','Bollinger','MACD','RSI']])\n",
        "    df_scaled = pd.DataFrame(df_scaled, columns=['OBV','Bollinger','MACD','RSI'], index=df.index)\n",
        "\n",
        "    # Add the scaled df\n",
        "    df = df.drop(['OBV','Bollinger','MACD','RSI'], axis=1)\n",
        "    df = pd.concat([df, df_scaled], axis=1)\n",
        "\n",
        "    # Convert df into weekly view\n",
        "    df = add_week(df)\n",
        "    df = group_into_weekly(df)\n",
        "\n",
        "    # Add target variable: {\"Up\": 1, \"Same/Down\": 0}\n",
        "    df = add_movement(df)\n",
        "\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Logistic regression\n",
        "\"\"\"\n",
        "def logistic_regression(X_train, y_train):\n",
        "\n",
        "    logreg = LogisticRegression(class_weight={0: 821, 1: 958})\n",
        "    grid={\"C\":np.logspace(-5,5,10)}\n",
        "    logreg_cv = GridSearchCV(logreg,grid,cv=5)\n",
        "    logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "    logreg.fit(X_train, y_train)\n",
        "    #pred = logreg.predict(X_test)\n",
        "    #print(\"Test accuracy: \", accuracy_score(pred, y_test))\n",
        "\n",
        "    return logreg"
      ],
      "metadata": {
        "id": "CrNDwGbkcivo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Random Forest\n",
        "\"\"\"\n",
        "def random_forest(X_train, y_train, show=False):\n",
        "\n",
        "    rfc=RandomForestClassifier()\n",
        "    rf_params = {\n",
        "        'n_estimators': [20, 50, 100],\n",
        "        'min_samples_split': list(range(2, 4)),\n",
        "        \"min_samples_leaf\": list(range(1, 3)),\n",
        "        \"max_depth\": [2, 3]\n",
        "    }\n",
        "\n",
        "    rf_grid = GridSearchCV(estimator=rfc, param_grid=rf_params)\n",
        "    rf_grid.fit(X_train, y_train)\n",
        "\n",
        "    if show:\n",
        "        print(\"Best params: \", rf_grid.best_estimator_.get_params())\n",
        "\n",
        "    best_rf = rf_grid.best_estimator_\n",
        "\n",
        "    return best_rf"
      ],
      "metadata": {
        "id": "SzwqaTFte2r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVzAnV3feKOq"
      },
      "source": [
        "\"\"\"\n",
        "Neural Network \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "class FeedForward(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_dim):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear modules and \n",
        "        assign them as member variables.\n",
        "        \"\"\"\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.lin_1 = torch.nn.Linear(input_size, hidden_dim)\n",
        "        self.lin_2 = torch.nn.Linear(hidden_dim, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Compute the forward pass of our model, which outputs logits.\n",
        "        \"\"\"\n",
        "        x = self.lin_1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        x = torch.from_numpy(np.array(X_test).astype(np.float32))\n",
        "        logits = self(x)\n",
        "        pred = torch.max(logits, 1)[1]\n",
        "\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT0nt6GLf_gJ"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def neural_network(X_train, y_train, show=False):\n",
        "\n",
        "    # initialize\n",
        "    nn_model = FeedForward(X_train.shape[1], 20)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(nn_model.parameters(), lr=1e-5)\n",
        "\n",
        "    for step in range(1, 50001):\n",
        "            \n",
        "        i = np.random.choice(X_train.shape[0], size=int(X_train.shape[0]/10), replace=False)\n",
        "        x = torch.from_numpy(np.array(X_train.iloc[i]).astype(np.float32))\n",
        "        y = torch.from_numpy(np.array(y_train.iloc[i]).astype(np.int))\n",
        "\n",
        "        # Forward pass: Get logits for x\n",
        "        logits = nn_model(x)\n",
        "        # Compute loss\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        # Zero gradients, perform a backward pass, and update the weights.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if show:\n",
        "            if step % 5000 == 0:\n",
        "                print(\"Current Step: \", step)\n",
        "                idxs = np.random.choice(len(X_train), int(X_train.shape[0]/10), replace=False)\n",
        "                x = torch.from_numpy(np.array(X_train.iloc[idxs]).astype(np.float32))\n",
        "                y = torch.from_numpy(np.array(y_train.iloc[idxs]).astype(np.int))\n",
        "                logits = nn_model(x)\n",
        "                loss = F.cross_entropy(logits, y)\n",
        "                y_pred = torch.max(logits, 1)[1]\n",
        "                print(\"Training Accuracy: \", accuracy_score(y_train.iloc[idxs], y_pred.numpy()))\n",
        "                print(\"Cross Entropy Loss: \", loss.item(), \"\\n\")\n",
        "\n",
        "    return nn_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Light GBM Model\n",
        "\"\"\"\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "def light_gbm(X_train, y_train):\n",
        "\n",
        "    X_train0, X_val= np.split(X_train, [int(0.8 *len(X_train))])\n",
        "    y_train0, y_val= np.split(y_train, [int(0.8 *len(y_train))])\n",
        "\n",
        "    train_dataset = lgb.Dataset(X_train0, label=y_train0)\n",
        "    val_dataset = lgb.Dataset(X_val, label = y_val)\n",
        "\n",
        "    param = {'num_leaves': 15, 'objective': 'binary'}\n",
        "    param['metric'] = 'auc'\n",
        "    num_round = 30\n",
        "    bst = lgb.train(param, train_dataset, num_round, valid_sets=[val_dataset], verbose_eval=-1)\n",
        "\n",
        "    return bst\n",
        "\n"
      ],
      "metadata": {
        "id": "bNds2fh1wv-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Backtester class\n",
        "\"\"\"\n",
        "\n",
        "class Backtester:\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  # data: data used for prediction\n",
        "  # price: actual closing prices on each Friday \n",
        "  # num_stocks: number of stocks to purchase each time\n",
        "  def performance(self, data, price, num_stocks = 10):\n",
        "\n",
        "    if type(self.model).__name__ == \"Booster\":\n",
        "        predictions = self.model.predict(data)\n",
        "        predictions = [1 if i >=0.5 else 0 for i in predictions]\n",
        "    else:\n",
        "        predictions = self.model.predict(data)\n",
        "\n",
        "    profit = 0\n",
        "    bought = False\n",
        "    for i in range(len(predictions)):\n",
        "      \n",
        "      # Assumption: if the closing price of this Friday shows an increase, then \n",
        "      # assume that next week will also increase, so will buy this Friday and\n",
        "      # sell next Friday no matter what (to simplify things)\n",
        "      if i == 0:\n",
        "        profit = profit - num_stocks * price[i]\n",
        "        bought = True\n",
        "        continue\n",
        "      else:\n",
        "        if bought:\n",
        "          profit = profit + num_stocks * price[i]\n",
        "          bought = False\n",
        "        if i == len(predictions):\n",
        "          break\n",
        "        if predictions[i] == 1:\n",
        "          profit = profit - num_stocks * price[i]\n",
        "          bought = True\n",
        "    \n",
        "    return profit, predictions"
      ],
      "metadata": {
        "id": "ESIxiMYvASEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Test with backtester - Test multiple companies\n",
        "\"\"\"\n",
        "ticker_list = [\"MSFT\",\"MCD\",\"TGT\"]  # Make a list of ticker symbols for Microsoft, McDonald's, Target\n",
        "y_list = {}  # Store actual test output for each company\n",
        "pred_list = {}  # Store prediction result for each company and each model \n",
        "\n",
        "for ticker in ticker_list:\n",
        "    df = preprocessing(ticker)\n",
        "\n",
        "    y = df[\"Target\"]\n",
        "\n",
        "    # Before we test our models, we want to find a baseline accuracy for our \n",
        "    # dataset by using the Zero Rule algorithm which predicts the most common \n",
        "    # class value for every entry.\n",
        "    for i in np.unique(y):\n",
        "        print(f'{len(y[y==i])} examples of class {i}')\n",
        "\n",
        "    val = y.mode()[0]\n",
        "    accuracy = len(y[y==val]) / len(y)\n",
        "    print(\"Baseline accuracy: \", accuracy, \"\\n\")\n",
        "\n",
        "    drop_cols = [c for c in df.columns if \"_5\" in c]\n",
        "    X = df.drop(drop_cols, axis=1)\n",
        "    X = X.drop(\"Target\", axis=1)\n",
        "\n",
        "    X_train, X_test= np.split(X, [int(0.9 *len(X))])\n",
        "    y_train, y_test= np.split(y, [int(0.9 *len(y))])\n",
        "    y_list[ticker] = y_test\n",
        "\n",
        "    # Train each model\n",
        "    logreg = logistic_regression(X_train, y_train)\n",
        "    rfc = random_forest(X_train, y_train)\n",
        "    nn_model = neural_network(X_train, y_train)\n",
        "    lgbm = light_gbm(X_train, y_train)\n",
        "\n",
        "    # Make a list of trained models\n",
        "    model_list = [logreg, rfc, nn_model, lgbm]\n",
        "\n",
        "    # Measure performances of each model with the back tester\n",
        "    for model in model_list:\n",
        "        tester = Backtester(model)\n",
        "        price = df.loc[y_test.index]['Close_5']\n",
        "\n",
        "        profit, pred = tester.performance(X_test, price)\n",
        "        print(\"Our projected profit with\", type(model).__name__, \"for\", ticker, \"is: \", profit)\n",
        "        print(\"Test Accuracy: \", accuracy_score(pred, y_test), \"\\n\")\n",
        "\n",
        "        # Store the predicted value \n",
        "        if ticker not in pred_list:\n",
        "            pred_list[ticker] = [pred]\n",
        "        else:\n",
        "            pred_list[ticker].append(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVmPcekvmAH6",
        "outputId": "0eef5eb1-ca63-4861-c805-e6d96faf5989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "692 examples of class 0\n",
            "863 examples of class 1\n",
            "Baseline accuracy:  0.554983922829582 \n",
            "\n",
            "Our projected profit with LogisticRegression for MSFT is:  -977.0\n",
            "Test Accuracy:  0.6346153846153846 \n",
            "\n",
            "Our projected profit with RandomForestClassifier for MSFT is:  -1109.0\n",
            "Test Accuracy:  0.6474358974358975 \n",
            "\n",
            "Our projected profit with FeedForward for MSFT is:  31.0\n",
            "Test Accuracy:  0.3717948717948718 \n",
            "\n",
            "Our projected profit with Booster for MSFT is:  -1968.3999999999983\n",
            "Test Accuracy:  0.5192307692307693 \n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "994 examples of class 0\n",
            "1125 examples of class 1\n",
            "Baseline accuracy:  0.5309108069844266 \n",
            "\n",
            "Our projected profit with LogisticRegression for MCD is:  -1228.6\n",
            "Test Accuracy:  0.6037735849056604 \n",
            "\n",
            "Our projected profit with RandomForestClassifier for MCD is:  413.40000000000055\n",
            "Test Accuracy:  0.4481132075471698 \n",
            "\n",
            "Our projected profit with FeedForward for MCD is:  -1228.6\n",
            "Test Accuracy:  0.6037735849056604 \n",
            "\n",
            "Our projected profit with Booster for MCD is:  359.30000000000064\n",
            "Test Accuracy:  0.46226415094339623 \n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "1023 examples of class 0\n",
            "1096 examples of class 1\n",
            "Baseline accuracy:  0.5172251061821614 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Display Confusion Matrices - to see precision.recall\n",
        "\"\"\"\n",
        "for i in range(4): \n",
        "    print(\"Confusion Matrices for\", type(model_list[i]).__name__)\n",
        "    for ticker in ticker_list:\n",
        "        print(\"<\", ticker, \">\")\n",
        "        matrix = confusion_matrix(y_list[ticker], pred_list[ticker][i], labels=[1,0])\n",
        "        display(matrix)\n",
        "        precision_up = matrix[0,0] / np.sum(matrix[:,0])\n",
        "        print(\"Up Precision:\", precision_up, \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E1Y5L_9maYun",
        "outputId": "5589cf5e-a5ea-4553-dd5a-de4f3af2661a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrices for LogisticRegression\n",
            "< MSFT >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[99,  0],\n",
              "       [57,  0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.6346153846153846 \n",
            "\n",
            "< MCD >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[128,   0],\n",
              "       [ 84,   0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.6037735849056604 \n",
            "\n",
            "< TGT >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[119,   6],\n",
              "       [ 80,   7]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.5979899497487438 \n",
            "\n",
            "Confusion Matrices for RandomForestClassifier\n",
            "< MSFT >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[94,  5],\n",
              "       [51,  6]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.6482758620689655 \n",
            "\n",
            "< MCD >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[86, 42],\n",
              "       [64, 20]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.5733333333333334 \n",
            "\n",
            "< TGT >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ 25, 100],\n",
              "       [ 16,  71]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.6097560975609756 \n",
            "\n",
            "Confusion Matrices for FeedForward\n",
            "< MSFT >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[99,  0],\n",
              "       [57,  0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.6346153846153846 \n",
            "\n",
            "< MCD >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[128,   0],\n",
              "       [ 83,   1]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.6066350710900474 \n",
            "\n",
            "< TGT >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[  7, 118],\n",
              "       [  1,  86]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.875 \n",
            "\n",
            "Confusion Matrices for Booster\n",
            "< MSFT >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[52, 47],\n",
              "       [28, 29]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.65 \n",
            "\n",
            "< MCD >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[58, 70],\n",
              "       [44, 40]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.5686274509803921 \n",
            "\n",
            "< TGT >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[71, 54],\n",
              "       [57, 30]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Up Precision: 0.5546875 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}